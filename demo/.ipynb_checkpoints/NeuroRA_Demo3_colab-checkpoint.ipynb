{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 3: a demo for comparing classification-based decoding and RSA\n",
    "Here is a demo based on the data of Bae&Luck's work in 2018. All demo data are based on their Experiment 2's data. You can find more details about the experiment and data information in their paper: Bae, G.Y., Luck, S.J. (2018). Dissociable decoding of spatial attention and working memory from eeg oscillations and sustained potentials. The Journal of Neuroscience, 38(2), 409-422."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install neurora\n",
    "! pip install pyctrsa\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from sklearn.svm import SVC\n",
    "from neurora.stuff import permutation_test\n",
    "from sklearn.metrics import accuracy_score\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from neurora.rdm_cal import eegRDM\n",
    "from neurora.rsa_plot import plot_rdm, plot_tbytsim_withstats\n",
    "from neurora.corr_cal_by_rdm import rdms_corr\n",
    "\n",
    "url = 'https://attachment.zhaokuangshi.cn/BaeLuck_2018jn_data_ERP_5subs.zip'\n",
    "filename = 'BaeLuck_2018jn_data_ERP_5subs.zip'\n",
    "data_dir = 'data/'\n",
    "classification_results_dir = 'classification_results/'\n",
    "ctrsa_results_dir = 'rsa_results/'\n",
    "filepath = data_dir + filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists!\n",
      "Unzip completes!\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "\n",
    "def show_progressbar(str, cur, total=100):\n",
    "\n",
    "    percent = '{:.2%}'.format(cur / total)\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str + \": [%-100s] %s\" % ('=' * int(cur), percent))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def schedule(blocknum,blocksize,totalsize):\n",
    "\n",
    "    if totalsize == 0:\n",
    "        percent = 0\n",
    "    else:\n",
    "        percent = blocknum * blocksize / totalsize\n",
    "    if percent > 1.0:\n",
    "        percent = 1.0\n",
    "    percent = percent * 100\n",
    "    show_progressbar(\"Downloading\", percent)\n",
    "\n",
    "exist = os.path.exists(filepath)\n",
    "if exist == False:\n",
    "    os.makedirs(data_dir)\n",
    "    urllib.request.urlretrieve(url, filepath, schedule)\n",
    "    print('Download completes!')\n",
    "elif exist == True:\n",
    "    print('Data already exists!')\n",
    "\n",
    "# unzip the data\n",
    "\n",
    "def unzipfile(filepath, data_dir):\n",
    "\n",
    "    with zipfile.ZipFile(filepath, 'r') as zip:\n",
    "        zip.extractall(data_dir)\n",
    "    print(\"Unzip completes!\")\n",
    "\n",
    "unzipfile(filepath, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Classification-based Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 27, 500)\n",
      "(640, 27, 500)\n",
      "(640, 27, 500)\n",
      "(640, 27, 500)\n",
      "(640, 27, 500)\n",
      "\n",
      "Orientation Decoding!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing for classification-based decoding\n",
    "\n",
    "# sub_ids\n",
    "subs = [\"201\", \"202\", \"203\", \"204\", \"205\"]\n",
    "\n",
    "exist = os.path.exists(data_dir + 'data_for_classification/ERP/')\n",
    "if exist == False:\n",
    "    os.makedirs(data_dir + 'data_for_classification/ERP/')\n",
    "\n",
    "for sub in subs:\n",
    "    data = sio.loadmat(data_dir + \"data/ERP\" + sub + \".mat\")[\"filtData\"][:, :, 250:]\n",
    "    print(data.shape)\n",
    "    # data.shape: n_trials, n_channels, n_times\n",
    "\n",
    "    ori_label = np.loadtxt(data_dir + \"labels/ori_\" + sub + \".txt\")[:, 1]\n",
    "    pos_label = np.loadtxt(data_dir + \"labels/pos_\" + sub + \".txt\")[:, 1]\n",
    "\n",
    "    ori_subdata500 = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "    pos_subdata500 = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "\n",
    "    ori_labelindex = np.zeros([16], dtype=np.int)\n",
    "    pos_labelindex = np.zeros([16], dtype=np.int)\n",
    "\n",
    "    for i in range(640):\n",
    "        label = int(ori_label[i])\n",
    "        ori_subdata500[label, ori_labelindex[label]] = data[i]\n",
    "        ori_labelindex[label] = ori_labelindex[label] + 1\n",
    "        label = int(pos_label[i])\n",
    "        pos_subdata500[label, pos_labelindex[label]] = data[i]\n",
    "        pos_labelindex[label] = pos_labelindex[label] + 1\n",
    "\n",
    "    ori_subdata = np.zeros([16, 40, 27, 100], dtype=np.float)\n",
    "    pos_subdata = np.zeros([16, 40, 27, 100], dtype=np.float)\n",
    "\n",
    "    for t in range(100):\n",
    "        ori_subdata[:, :, :, t] = np.average(ori_subdata500[:, :, :, t * 5:t * 5 + 5], axis=3)\n",
    "        pos_subdata[:, :, :, t] = np.average(pos_subdata500[:, :, :, t * 5:t * 5 + 5], axis=3)\n",
    "\n",
    "    f = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"w\")\n",
    "    f.create_dataset(\"ori\", data=ori_subdata)\n",
    "    f.create_dataset(\"pos\", data=pos_subdata)\n",
    "    f.close()\n",
    "\n",
    "# aftering the preprocessing above,\n",
    "# we can obtain ERP data of orientation and position for each subject\n",
    "# each subject's orientation ERP data's shape is [16, 40, 27, 100]\n",
    "# 16: the number of conditions (here means 16 different orientation degrees)\n",
    "# 40: the number of trials\n",
    "# 27: the number of channels\n",
    "# 100: the number of time-points (from -500 ms to 1500 ms, sample rate: 50 Hz)\n",
    "\n",
    "# Linear-SVM decoding\n",
    "\n",
    "exist = os.path.exists(classification_results_dir)\n",
    "if exist == False:\n",
    "    os.makedirs(classification_results_dir)\n",
    "\n",
    "# orientation decoding\n",
    "print(\"\\nOrientation Decoding!\")\n",
    "subindex = 0\n",
    "if os.path.exists(classification_results_dir + \"ERP_ori.h5\"):\n",
    "    os.remove(classification_results_dir + \"ERP_ori.h5\")\n",
    "f = h5py.File(classification_results_dir + \"ERP_ori.h5\", \"w\")\n",
    "total = len(subs) * 10 * 3 * 100\n",
    "for sub in subs:\n",
    "    fdata = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"r\")\n",
    "    data = np.array(fdata[\"ori\"])\n",
    "    fdata.close()\n",
    "    acc = np.zeros([10, 100, 3], dtype=np.float)\n",
    "    for k in range(10):\n",
    "        index_trials = np.array(range(40))\n",
    "        shuffle = np.random.permutation(index_trials)\n",
    "        newdata = data[:, shuffle[:39]]\n",
    "        block_data = np.zeros([3, 16, 27, 100], dtype=np.float)\n",
    "        for i in range(3):\n",
    "            block_data[i] = np.average(newdata[:, i * 13:i * 13 + 13], axis=1)\n",
    "        y_train = np.zeros([2 * 16], dtype=np.int)\n",
    "        for i in range(2):\n",
    "            for j in range(16):\n",
    "                y_train[i * 16 + j] = j\n",
    "        y_test = np.zeros([16], dtype=np.int)\n",
    "        for i in range(16):\n",
    "            y_test[i] = i\n",
    "        for i in range(3):\n",
    "            x_test = block_data[i]\n",
    "            x_train = np.zeros([2, 16, 27, 100], dtype=np.float)\n",
    "            index = 0\n",
    "            for j in range(3):\n",
    "                if j != i:\n",
    "                    x_train[index] = block_data[j]\n",
    "                    index = index + 1\n",
    "            x_train = np.reshape(x_train, [2 * 16, 27, 100])\n",
    "            for t in range(100):\n",
    "                x_train_t = x_train[:, :, t]\n",
    "                x_test_t = x_test[:, :, t]\n",
    "                svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "                svm.fit(x_train_t, y_train)\n",
    "                y_pred = svm.predict(x_test_t)\n",
    "                acc[k, t, i] = accuracy_score(y_test, y_pred)\n",
    "    subindex = subindex + 1\n",
    "    f.create_dataset(sub, data=np.average(acc, axis=(0, 2)))\n",
    "f.close()\n",
    "\n",
    "# orientation decoding\n",
    "print(\"\\nPosition Decoding!\")\n",
    "subindex = 0\n",
    "f = h5py.File(classification_results_dir + \"ERP_pos.h5\", \"w\")\n",
    "total = len(subs) * 10 * 3 * 100\n",
    "for sub in subs:\n",
    "    fdata = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"r\")\n",
    "    data = np.array(fdata[\"pos\"])\n",
    "    fdata.close()\n",
    "    acc = np.zeros([10, 100, 3], dtype=np.float)\n",
    "    for k in range(10):\n",
    "        index_trials = np.array(range(40))\n",
    "        shuffle = np.random.permutation(index_trials)\n",
    "        newdata = data[:, shuffle[:39]]\n",
    "        block_data = np.zeros([3, 16, 27, 100], dtype=np.float)\n",
    "        for i in range(3):\n",
    "            block_data[i] = np.average(newdata[:, i * 13:i * 13 + 13], axis=1)\n",
    "        y_train = np.zeros([2 * 16], dtype=np.int)\n",
    "        for i in range(2):\n",
    "            for j in range(16):\n",
    "                y_train[i * 16 + j] = j\n",
    "        y_test = np.zeros([16], dtype=np.int)\n",
    "        for i in range(16):\n",
    "            y_test[i] = i\n",
    "        for i in range(3):\n",
    "            x_test = block_data[i]\n",
    "            x_train = np.zeros([2, 16, 27, 100], dtype=np.float)\n",
    "            index = 0\n",
    "            for j in range(3):\n",
    "                if j != i:\n",
    "                    x_train[index] = block_data[j]\n",
    "                    index = index + 1\n",
    "            x_train = np.reshape(x_train, [2 * 16, 27, 100])\n",
    "            for t in range(100):\n",
    "                x_train_t = x_train[:, :, t]\n",
    "                x_test_t = x_test[:, :, t]\n",
    "                svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "                svm.fit(x_train_t, y_train)\n",
    "                y_pred = svm.predict(x_test_t)\n",
    "                acc[k, t, i] = accuracy_score(y_test, y_pred)\n",
    "    subindex = subindex + 1\n",
    "    f.create_dataset(sub, data=np.average(acc, axis=(0, 2)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Plot the classification-based decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the classification-based decoding results\n",
    "\n",
    "# a function for plotting the time-by-time decoding results\n",
    "def plot_tbytresults(decoding_results_dir, subs):\n",
    "    f = h5py.File(decoding_results_dir, \"r\")\n",
    "    nsubs = len(subs)\n",
    "    rlts = np.zeros([nsubs, 100], dtype=np.float)\n",
    "    subindex = 0\n",
    "    for sub in subs:\n",
    "        rlts[subindex] = np.array(f[sub])\n",
    "        for t in range(100):\n",
    "            if t <= 1:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, :t + 3])\n",
    "            if t > 1 and t < 98:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, t - 2:t + 3])\n",
    "            if t >= 98:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, t - 2:])\n",
    "        subindex = subindex + 1\n",
    "    f.close()\n",
    "\n",
    "    avg = np.average(rlts, axis=0)\n",
    "    err = np.zeros([100], dtype=np.float)\n",
    "    for t in range(100):\n",
    "        err[t] = np.std(rlts[:, t], ddof=1) / np.sqrt(nsubs)\n",
    "\n",
    "    ps = np.zeros([100], dtype=np.float)\n",
    "    chance = np.full([len(subs)], 0.0625)\n",
    "    for t in range(100):\n",
    "        ps[t] = permutation_test(rlts[:, t], chance)\n",
    "        if ps[t] < 0.05 and avg[t] > 0.0625:\n",
    "            plt.plot(t * 0.02 - 0.5, 0.148, \"s\", color=\"orangered\", alpha=0.8)\n",
    "            xi = [t * 0.02 - 0.5, t * 0.02 + 0.02 - 0.5]\n",
    "            ymin = [0.0625]\n",
    "            ymax = [avg[t] - err[t]]\n",
    "            plt.fill_between(xi, ymax, ymin, facecolor=\"orangered\", alpha=0.15)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(3)\n",
    "    ax.spines[\"bottom\"].set_linewidth(3)\n",
    "    ax.spines['bottom'].set_position(('data', 0.0625))\n",
    "    x = np.arange(-0.5 + 0.008, 1.5 + 0.008, 0.02)\n",
    "    plt.fill_between(x, avg + err, avg - err, facecolor=\"orangered\", alpha=0.8)\n",
    "    plt.ylim(0.05, 0.15)\n",
    "    plt.xlim(-0.5, 1.5)\n",
    "    plt.xticks([-0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5])\n",
    "    plt.tick_params(labelsize=12)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=16)\n",
    "    plt.ylabel(\"Classification Accuracy\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# plot orientation decoding results\n",
    "print(\"Orientation Classification-based Decoding Results!\")\n",
    "plot_tbytresults(classification_results_dir + \"ERP_ori.h5\", subs)\n",
    "\n",
    "# plot position decoding results\n",
    "print(\"Position Classification-based Decoding Results!\")\n",
    "plot_tbytresults(classification_results_dir + \"ERP_pos.h5\", subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: RSA-based Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing for classification-based decoding\n",
    "\n",
    "if os.path.exists(data_dir + 'data_for_RSA/ERP/') == False:\n",
    "    os.makedirs(data_dir + 'data_for_RSA/ERP/')\n",
    "\n",
    "n = len(subs)\n",
    "subindex = 0\n",
    "for sub in subs:\n",
    "    data = sio.loadmat(data_dir + \"data/ERP\" + sub + \".mat\")[\"filtData\"][:, :, 250:]\n",
    "    # data.shape: n_trials, n_channels, n_times\n",
    "\n",
    "    ori_label = np.loadtxt(data_dir + \"labels/ori_\" + sub + \".txt\")[:, 1]\n",
    "    pos_label = np.loadtxt(data_dir + \"labels/pos_\" + sub + \".txt\")[:, 1]\n",
    "\n",
    "    ori_subdata = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "    pos_subdata = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "\n",
    "    ori_labelindex = np.zeros([16], dtype=np.int)\n",
    "    pos_labelindex = np.zeros([16], dtype=np.int)\n",
    "\n",
    "    for i in range(640):\n",
    "        label = int(ori_label[i])\n",
    "        ori_subdata[label, ori_labelindex[label]] = data[i]\n",
    "        ori_labelindex[label] = ori_labelindex[label] + 1\n",
    "        label = int(pos_label[i])\n",
    "        pos_subdata[label, pos_labelindex[label]] = data[i]\n",
    "        pos_labelindex[label] = pos_labelindex[label] + 1\n",
    "\n",
    "    f = h5py.File(data_dir + \"data_for_RSA/ERP/\" + sub + \".h5\", \"w\")\n",
    "    f.create_dataset(\"ori\", data=ori_subdata)\n",
    "    f.create_dataset(\"pos\", data=pos_subdata)\n",
    "    f.close()\n",
    "    print(sub)\n",
    "\n",
    "nsubs = len(subs)\n",
    "data_ori_ERP = np.zeros([16, nsubs, 40, 27, 500], dtype=np.float)\n",
    "data_pos_ERP = np.zeros([16, nsubs, 40, 27, 500], dtype=np.float)\n",
    "subindex = 0\n",
    "for sub in subs:\n",
    "    print('Loading data of sub'+sub)\n",
    "    f = h5py.File(data_dir+'data_for_RSA/ERP/'+sub+'.h5', 'r')\n",
    "    ori_subdata = np.array(f['ori'])\n",
    "    pos_subdata = np.array(f['pos'])\n",
    "    f.close()\n",
    "    data_ori_ERP[:, subindex] = ori_subdata\n",
    "    data_pos_ERP[:, subindex] = pos_subdata\n",
    "    subindex = subindex + 1\n",
    "\n",
    "# calculate the RDMs\n",
    "\n",
    "print(\"\\nCalculate the Orientation RDMs!\")\n",
    "RDM_ori_ERP = eegRDM(data_ori_ERP, sub_opt=1, chl_opt=0, time_opt=1, time_win=5, time_step=5)\n",
    "print(\"\\nCalculate the Position RDMs!\")\n",
    "RDM_pos_ERP = eegRDM(data_pos_ERP, sub_opt=1, chl_opt=0, time_opt=1, time_win=5, time_step=5)\n",
    "# shape of RDMs: [5, 100, 16, 16]\n",
    "\n",
    "# establish a Coding RDM\n",
    "model_RDM = np.zeros([16, 16], dtype=np.float)\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        diff = np.abs(i - j)\n",
    "        if diff <= 8:\n",
    "            model_RDM[i, j] = diff / 8\n",
    "        else:\n",
    "            model_RDM[i, j] = (16 - diff) / 8\n",
    "\n",
    "conditions = [\"0°\", \"22.5°\", \"45°\", \"67.5°\", \"90°\", \"112.5°\", \"135°\", \"157.5°\", \"180°\",\n",
    "              \"202.5°\", \"225°\", \"247.5°\", \"270°\", \"292.5°\", \"315°\", \"337.5°\"]\n",
    "\n",
    "# plot the Coding RDM\n",
    "print(\"Coding RDM!\")\n",
    "plot_rdm(model_RDM, percentile=True, conditions=conditions)\n",
    "\n",
    "# calculate the CTSimilarities between CTRDMs and Coding RDM\n",
    "print(\"\\nCalculate the Similarities of Orientation!\")\n",
    "Sim_ori_ERP = rdms_corr(model_RDM, RDM_ori_ERP)\n",
    "print(\"\\nCalculate the Similarities of Position!\")\n",
    "Sim_pos_ERP = rdms_corr(model_RDM, RDM_pos_ERP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Plot the RSA-based decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot orientation decoding results\n",
    "print(\"Orientation RSA-based Decoding Results!\")\n",
    "plot_tbytsim_withstats(Sim_ori_ERP, start_time=-0.5, end_time=1.5, color='orange', lim=[-0.1, 0.5])\n",
    "\n",
    "# plot position decoding results\n",
    "print(\"Position RSA-based Decoding Results!\")\n",
    "plot_tbytsim_withstats(Sim_pos_ERP, start_time=-0.5, end_time=1.5, color='orange', lim=[-0.1, 0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
